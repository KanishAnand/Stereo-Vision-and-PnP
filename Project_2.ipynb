{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 2\n",
    "\n",
    "## Topic : Stereo reconstruction and Non-linear optimization\n",
    "\n",
    "#### Instructions\n",
    "<ul>\n",
    "    <li> The second project of the course is designed to get you familiar with stereo reconstruction, and non-linear optimization </li>\n",
    "    <li> Use python for this project. PILLOW and OpenCV are permitted for image I/O. </li>\n",
    "    <li> Submit this notebook as a zipped file on moodle. The format should be $<$team_id$>$_$<$team_ name$>$.zip. Both members have to submit this zip file. </li>\n",
    "    <li> A seperate report is not needed if you're coding in the notebook itself. Please provide adequate descriptions of the approaches you've taken. Also mention work distribution for the two members. </li>\n",
    "    <li> Refer to the late day policy. Start early </li> \n",
    "    <li> Download data from here: https://iiitaphyd-my.sharepoint.com/:f:/g/personal/aryan_sakaria_students_iiit_ac_in/Er5C7351IAlFsvwHUesFeSQBQtlSiAS7AORSEJT2qH_8_w?e=ol98k9  </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "### PART 1: Stereo dense reconstruction\n",
    "\n",
    "3-D point clouds are very useful in robotics for several tasks such as object detection, motion estimation (3D-3D matching or 3D-2D matching), SLAM, and other forms of scene understanding.  Stereo camerasprovide  us  with  a  convenient  way  to  generate  dense  point  clouds.Densehere,  in  contrast  tosparse,means all the image points are used for the reconstruction.  In this part of the assignment you will begenerating a dense 3D point cloud reconstruction of a scene from stereo images.\n",
    "\n",
    "#### Procedure: \n",
    "\n",
    "<ol>\n",
    "    <li> Generate a disparity map for each stereo pair.  Use OpenCV (e.g.  StereoSGBM) for this.  Notethat the images provided are already rectified and undistorted. </li>\n",
    "    <li> Then, using the camera parameters and baseline information generate colored point clouds fromeach disparity map.  Some points will have invalid disparity values, so ignore them.  Use [Open3D]for storing your point clouds. </li>\n",
    "    <li> Register (or transform) all the generated point clouds into your world frame by using the providedground truth poses. </li>\n",
    "    <li> Visualize the registered point cloud data, in color.  Use Open3D for this </li>\n",
    "</ol>\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries:\n",
    "import numpy as np \n",
    "# from sklearn.preprocessing import normalize #normalizing gives better results. Experiment with this\n",
    "import cv2\n",
    "import open3d as o3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_transformations(filename = \"mr2020_project_data/poses.txt\"):\n",
    "    arr = np.loadtxt(filename)\n",
    "    return arr\n",
    "#     f = open(filename, 'r')\n",
    "#     lines = f.readlines()\n",
    "#     transformation_list = []\n",
    "    \n",
    "#     for i in range(len(lines)):\n",
    "#         transformation_list_temp = lines[i].split()        \n",
    "#         temp_rot = [] \n",
    "#         temp_rot.append( transformation_list_temp[0:4]  ) \n",
    "#         temp_rot.append( transformation_list_temp[4:8]   ) \n",
    "#         temp_rot.append( transformation_list_temp[8:12]   ) \n",
    "#         transformation_list.append(temp_rot)\n",
    "#     return transformation_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def read_calibrations(filename = \"mr2020_project_data/calib.txt\"):\n",
    "#     f = open(filename, 'r')\n",
    "#     lines = f.readlines()\n",
    "#     for line in lines:\n",
    "#         p = line.split('\\n')\n",
    "#         print(p[0])\n",
    "        \n",
    "# read_calibrations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = np.array([[7.070912e+02, 0.000000e+00, 6.018873e+02], \n",
    "              [0.000000e+00, 7.070912e+02, 1.831104e+02], \n",
    "              [0.000000e+00, 0.000000e+00, 1.000000e+00]])\n",
    "D = 0.53790448812"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Provide explanation in this cell: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "LEFT_IMAGE_PATH = \"mr2020_project_data/img2\"\n",
    "RIGHT_IMAGE_PATH = \"mr2020_project_data/img3\"\n",
    "PC_PATH = 'point_clouds'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_ply(vertices, colors, filename):\n",
    "    colors = colors.reshape(-1,3)\n",
    "    vertices = np.hstack([vertices.reshape(-1,3), colors])\n",
    "\n",
    "    ply_header = '''ply\n",
    "        format ascii 1.0\n",
    "        element vertex %(vert_num)d\n",
    "        property float x\n",
    "        property float y\n",
    "        property float z\n",
    "        property uchar red\n",
    "        property uchar green\n",
    "        property uchar blue\n",
    "        end_header\n",
    "        '''\n",
    "    with open(filename, 'w') as f:\n",
    "        f.write(ply_header %dict(vert_num=len(vertices)))\n",
    "        np.savetxt(f,vertices,'%f %f %f %d %d %d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def make_disparitymap(img_left, img_right):\n",
    "    imgL = cv2.imread(img_left)\n",
    "    imgR = cv2.imread(img_right)\n",
    "\n",
    "    imgL = cv2.cvtColor(imgL, cv2.COLOR_BGR2GRAY)\n",
    "    imgR = cv2.cvtColor(imgR, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # change its parameters\n",
    "    stereo = cv2.StereoSGBM_create()\n",
    "    disparity = stereo.compute(imgL,imgR).astype(np.float32)\n",
    "    \n",
    "    return disparity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "transformations = read_transformations()\n",
    "\n",
    "if not os.path.isdir(PC_PATH):\n",
    "    os.mkdir(PC_PATH)\n",
    "\n",
    "for file_name in sorted(os.listdir(LEFT_IMAGE_PATH)):\n",
    "    img_left = os.path.join(LEFT_IMAGE_PATH, file_name)\n",
    "    img_right = os.path.join(RIGHT_IMAGE_PATH, file_name)\n",
    "    \n",
    "    disparity = make_disparitymap(img_left, img_right)\n",
    "    \n",
    "    # disparity value was coming negative so\n",
    "    # https://dsp.stackexchange.com/questions/25786/can-disparity-range-from-negative-to-positive-values-for-parallel-cameras\n",
    "    disparity += abs(disparity.min())\n",
    "    print(disparity.min())\n",
    "    \n",
    "    img = cv2.imread(img_left)\n",
    "    \n",
    "#     rev_proj_matrix = np.zeros((4,4)) \n",
    "    \n",
    "#     cv2.stereoRectify(cameraMatrix1 = K, cameraMatrix2 = K, \n",
    "#                       distCoeffs1 = 0, distCoeffs2 = 0,\n",
    "#                       imageSize = img.shape[:2],\n",
    "#                       R = np.identity(3), T = np.array([D, 0., 0.]),\n",
    "#                       Q = rev_proj_matrix)\n",
    "    \n",
    "#     h, w = img.shape[:2]\n",
    "#     f = 7.070912e+02\n",
    "#     rev_proj_matrix = np.float32([[1, 0, 0, -0.5*w],\n",
    "#                         [0,-1, 0,  0.5*h], \n",
    "#                         [0, 0, 0, -f], \n",
    "#                         [0, 0, -1/D,  0]])\n",
    "    \n",
    "    points = cv2.reprojectImageTo3D(disparity, rev_proj_matrix)\n",
    "    \n",
    "    colors = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  \n",
    "    \n",
    "    mask = disparity > disparity.min()\n",
    "    points = points[mask]\n",
    "    colors = colors[mask]\n",
    "    write_ply(points, colors,  os.path.join(PC_PATH, file_name[: -4] + \".ply\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# applying transformations per point cloud and joining all point clouds\n",
    "transformations = read_transformations()\n",
    "\n",
    "pcd = o3d.geometry.PointCloud()\n",
    "cnt = 0\n",
    "\n",
    "for trans_mat, file_name in zip(transformations,sorted(os.listdir(PC_PATH))):\n",
    "    point_cloud = o3d.io.read_point_cloud(os.path.join(PC_PATH, file_name))\n",
    "    trans_mat = trans_mat.reshape(3, 4)\n",
    "    trans_mat = np.vstack((trans_mat, [0,0,0,1]))\n",
    "    point_cloud = point_cloud.transform(trans_mat)\n",
    "    pcd += point_cloud\n",
    "    \n",
    "# o3d.visualization.draw_geometries([pcd])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "### PART 2: Motion estimation using iterative PnP\n",
    "\n",
    "Using the generated reconstruction from the previous part, synthesize a new image taken by a virtualmonocular camera fixed at any arbitrary position and orientation.  Your task in this part is to recoverthis pose using an iterative Perspective-from-n-Points (PnP) algorithm. \n",
    "\n",
    "#### Procedure: \n",
    "\n",
    "<ol>\n",
    "    <li> Obtain a set of 2D-3D correspondences between the the image and the point cloud.  Since hereyou’re generating the image, this should be easy to obtain. </li>\n",
    "    <li> For this set of correspondences compute the total reprojection error c= $\\sum_{i} ‖x_i−P_{k}X_i‖^2 $    where $P_{k}= K[R_{k}|t_{k}]$, $X_{i}$ is the 3D point in the world frame, $x_{i}$ is its corresponding projection. </li>\n",
    "    <li> Solve for the pose $T_{k}$ that minimizes this non-linear reprojection error using a Gauss-Newton (GN)scheme.  Recall that in GN we start with some initial estimated value $x_{o}$ and iteratively refine the estimate using $x_{1}$= $∆x+x_0$, where $∆x$ is obtained by solving the normal equations $J^{T}J∆x$= -$J^{T}e$, until convergence.The main steps in this scheme are computing the corresponding Jacobians and updating the estimates correctly.  For our problem,  use a 12×1 vector parameterization for $T_{k}$(the top 3×4submatrix).  Run the optimization for different choices of initialization and report your observations. </li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8293202, 3)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points = np.asarray(pcd.points)\n",
    "points.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.zeros((12,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "a[0] = 2\n",
    "a[5] = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [4.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.]])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20.0"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(a**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2., 0., 0., 0.],\n",
       "       [0., 4., 0., 0.],\n",
       "       [0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.reshape((3,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.3089785e+03 1.3089785e+03 1.3089785e+03 1.3089785e+03]\n",
      " [8.9020160e+02 8.9020160e+02 8.9020160e+02 8.9020160e+02]\n",
      " [1.0000000e+00 1.0000000e+00 1.0000000e+00 1.0000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "R = np.array([[1, 1, 1], [1, 1, 1], [1, 1, 1]])\n",
    "t = np.array([[1],\n",
    "             [1],\n",
    "             [1]])\n",
    "\n",
    "P = K @ np.hstack((R,t))\n",
    "print(P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "points_3d = []\n",
    "points_2d = []\n",
    "\n",
    "for i in range(0, points.shape[0], 100):\n",
    "    # making homogenous coordinates\n",
    "    pnt = P @ np.hstack((points[i], [1]))\n",
    "    points_3d.append(np.hstack((points[i], [1])))\n",
    "    points_2d.append(pnt)\n",
    "\n",
    "points_3d = np.array(points_3d)\n",
    "points_2d = np.array(points_2d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def residual(points_2d, points_3d, P):\n",
    "    res = []\n",
    "    P = P.reshape((3,4))\n",
    "\n",
    "    for i in range(points_2d.shape[0]):\n",
    "        proj_point = P @ points_3d[i]\n",
    "        norm = (points_2d[i] - proj_point)**2\n",
    "        e = np.sum(norm)\n",
    "        res.append(e)\n",
    "        \n",
    "    return np.array(res)\n",
    "     \n",
    "def jacobian(points_2d, points_3d, P):\n",
    "    J = np.zeros((points_2d.shape[0], 12))\n",
    "    \n",
    "    for i in range(points_2d.shape[0]):\n",
    "        x1, x2, x3 = points_2d[i]\n",
    "        X1, X2, X3, X4 = points_3d[i]\n",
    "\n",
    "        J[i][0] = 2*(x1 - P[0]*X1 - P[1]*X2 - P[2]*X3 - P[3]*X4)* (-X1)\n",
    "        J[i][1] = 2*(x1 - P[0]*X1 - P[1]*X2 - P[2]*X3 - P[3]*X4)* (-X2)\n",
    "        J[i][2] = 2*(x1 - P[0]*X1 - P[1]*X2 - P[2]*X3 - P[3]*X4)* (-X3)\n",
    "        J[i][3] = 2*(x1 - P[0]*X1 - P[1]*X2 - P[2]*X3 - P[3]*X4)* (-X4)\n",
    "\n",
    "        J[i][4] = 2*(x1 - P[4]*X1 - P[5]*X2 - P[6]*X3 - P[7]*X4)* (-X1)\n",
    "        J[i][5] = 2*(x1 - P[4]*X1 - P[5]*X2 - P[6]*X3 - P[7]*X4)* (-X2)\n",
    "        J[i][6] = 2*(x1 - P[4]*X1 - P[5]*X2 - P[6]*X3 - P[7]*X4)* (-X3)\n",
    "        J[i][7] = 2*(x1 - P[4]*X1 - P[5]*X2 - P[6]*X3 - P[7]*X4)* (-X4)\n",
    "\n",
    "        J[i][8] = 2*(x1 - P[8]*X1 - P[9]*X2 - P[10]*X3 - P[11]*X4)* (-X1)\n",
    "        J[i][9] = 2*(x1 - P[8]*X1 - P[9]*X2 - P[10]*X3 - P[11]*X4)* (-X2)\n",
    "        J[i][10] = 2*(x1 - P[8]*X1 - P[9]*X2 - P[10]*X3 - P[11]*X4)* (-X3)\n",
    "        J[i][11] = 2*(x1 - P[8]*X1 - P[9]*X2 - P[10]*X3 - P[11]*X4)* (-X4)\n",
    "        \n",
    "    return J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12,)\n",
      "[319.06363144 319.06363144 319.06363144 319.06363139 319.06363144\n",
      " 319.06363144 319.06363144 319.06363138 319.06363144 319.06363144\n",
      " 319.06363144 319.06363139]\n"
     ]
    }
   ],
   "source": [
    "ITERATIONS = 1\n",
    "\n",
    "# initialize with all 0's\n",
    "proj = np.zeros((12,1))\n",
    "\n",
    "for _ in range(ITERATIONS):\n",
    "    J = jacobian(points_2d, points_3d, proj)\n",
    "    e = residual(points_2d, points_3d, proj)\n",
    "    # J^T @ J @ del_x = - J^T @ e\n",
    "    del_proj = - np.linalg.inv(J.T @ J) @ J.T @ e \n",
    "    print(del_proj.shape)\n",
    "    print(del_proj)\n",
    "    proj += del_proj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(4.37320238e+10)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
